{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "from model import linear_regression\n",
    "from model import logistic_regression\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join('train_features.csv'))\n",
    "val = pd.read_csv(os.path.join('val_features.csv'))\n",
    "test = pd.read_csv(os.path.join('test_features.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data_x = data.drop(['Headline', 'articleBody', 'headline_vec', 'body_vec', 'Body ID',\n",
    "                           'tf_idf_eucliden_dis', 'tf_idf_Manhattan_dis', 'Stance'], axis=1)\n",
    "    data_y = pd.get_dummies(data['Stance'])\n",
    "    scaler = preprocessing.MinMaxScaler()\n",
    "    scaled_df = scaler.fit_transform(data_x)\n",
    "    data_x.loc[:,:] = scaled_df\n",
    "    return data_x, data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = preprocess(train.copy())\n",
    "val_x, val_y = preprocess(val.copy())\n",
    "test_x, test_y = preprocess(test.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tf_idf_cos_sim</th>\n",
       "      <th>common_words_count</th>\n",
       "      <th>KL_divergence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.251449</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.319306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119022</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.313937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.223101</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.184358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.266811</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.210090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.307222</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.251412</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tf_idf_cos_sim  common_words_count  KL_divergence\n",
       "0        0.251449            0.148148       0.319306\n",
       "1        0.119022            0.148148       0.313937\n",
       "2        0.223101            0.222222       0.184358\n",
       "3        0.266811            0.370370       0.210090\n",
       "4        0.307222            0.222222       0.251412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y, y_pred):\n",
    "    return sum(np.sum(y_pred == y, axis=1) == 4) / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracies(model, epochs, eta):\n",
    "    train_preds = train_y.copy()\n",
    "    val_preds = val_y.copy()\n",
    "    test_preds = test_y.copy()\n",
    "    for col in train_preds.columns:\n",
    "        train_preds[col] = 0\n",
    "        val_preds[col] = 0\n",
    "        test_preds[col] = 0\n",
    " \n",
    "    labels = train_preds.columns\n",
    "\n",
    "    for label in labels:\n",
    "        model.fit(train_x, train_y[label].to_frame(), epochs, eta)\n",
    "        train_preds[label] = model.predict(train_x)\n",
    "        val_preds[label] = model.predict(val_x)\n",
    "        test_preds[label] = model.predict(test_x)\n",
    "    \n",
    "    \n",
    "    train_preds = multi_class_predict(train_preds)\n",
    "    val_preds = multi_class_predict(val_preds)\n",
    "    test_preds = multi_class_predict(test_preds)\n",
    "    \n",
    "    return accuracy(train_preds, train_y), accuracy(val_preds, val_y), accuracy(test_preds, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7220320308503522"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_y = np.zeros((len(test_x), 4))\n",
    "base_y[:,3] = 1\n",
    "accuracy(test_y, base_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_predict(y):\n",
    "#     max_cols = y.idxmax(axis=1, skipna=True).values\n",
    "    y = np.array(y)\n",
    "    max_col_values = np.amax(y, axis=1)\n",
    "    for i in range(len(y)):\n",
    "        y[i] = y[i] >= max_col_values[i]\n",
    "#     labels = y.columns\n",
    "#     for i, row in y.iterrows():\n",
    "#         for label in labels:\n",
    "#             row[label] = 0.0\n",
    "#         max_col = max_cols[i]\n",
    "#         row[max_col] = 1.0 \n",
    "    return y * 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8703695468492907, 0.885954381752701, 0.8552709243300672)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_regression()\n",
    "calculate_accuracies(model, 3000, 0.061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8755058478231867, 0.8873549419767908, 0.8582615196946445)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logistic_regression()\n",
    "calculate_accuracies(model, 3000, 0.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigate learning rate effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_errors(model, epochs):\n",
    "    etas = [x / 100 for x in list(range(2, 100, 5))]\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "    test_errors = []\n",
    "    for eta in etas:\n",
    "        train_error, val_error, test_error = calculate_accuracies(model, epochs, eta)\n",
    "        train_errors.append(train_error)\n",
    "        val_errors.append(val_error)\n",
    "        test_errors.append(test_error)\n",
    "    \n",
    "    errors = [train_errors, val_errors, test_errors]\n",
    "    labels = ['train_error', 'val_error', 'test_error']\n",
    "\n",
    "    for error, label in zip(errors, labels):\n",
    "        plt.plot(etas, error, label=label)\n",
    "    plt.legend()\n",
    "    plt.xlabel('learning rate')\n",
    "    plt.ylabel('Training, val and testing errors')\n",
    "    plt.title('Investigating the impacts of changing learning rate on the errors')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = linear_regression()\n",
    "# plot_errors(model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = logistic_regression()\n",
    "# plot_errors(model, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_best_feature(model, epochs, eta):\n",
    "\n",
    "    labels = train_y.columns\n",
    "    features = train_x.columns\n",
    "\n",
    "    val_accuracy = calculate_accuracies(model, epochs, eta)[1]\n",
    "    max_acc_reduction, best_feature = 0, ''\n",
    "    \n",
    "    for feature in features:\n",
    "        train_preds = train_y.copy()\n",
    "        val_preds = val_y.copy()\n",
    "        for label in labels:\n",
    "            new_train_x = train_x.copy().drop(feature, axis=1)\n",
    "            new_val_x = val_x.copy().drop(feature, axis=1)\n",
    "            \n",
    "            model.fit(new_train_x, train_y[label].to_frame(), epochs, eta)\n",
    "            val_preds[label] = model.predict(new_val_x)      \n",
    "        val_preds = multi_class_predict(val_preds)\n",
    "        acc_reduction = (val_accuracy - accuracy(val_preds, val_y))\n",
    "        print(feature + ' : ' + str(acc_reduction))\n",
    "        if acc_reduction > max_acc_reduction:\n",
    "            max_acc_reduction = acc_reduction\n",
    "            best_feature = feature\n",
    "            \n",
    "    return best_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf_cos_sim : 0.019807923169267605\n",
      "common_words_count : 0.0006002400960383181\n",
      "KL_divergence : 0.004801920768307322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'tf_idf_cos_sim'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = linear_regression()\n",
    "calc_best_feature(model, 3000, 0.061)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_idf_cos_sim : 0.02200880352140866\n",
      "common_words_count : 0.001400560224089742\n",
      "KL_divergence : 0.27871148459383754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'KL_divergence'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = logistic_regression()\n",
    "calc_best_feature(model, 3000, 0.36)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
